"use client";

import { useRef, useState } from "react";
import {
  callIpa,
  callStt,
  callLipSync,
  callPronEval,
  SttResp,
  IpaResp,
  PronReport,
  AiFeedback,
} from "@/lib/api";

type Phase =
  | "ëŒ€ê¸° ì¤‘"
  | "ë…¹ìŒ ì¤‘"
  | "ì—…ë¡œë“œ ì¤‘"
  | "ì²˜ë¦¬ ì¤‘"
  | "ì™„ë£Œ"
  | "ì˜¤ë¥˜";

export default function RecorderWithViz() {
  const [phase, setPhase] = useState<Phase>("ëŒ€ê¸° ì¤‘");
  const [err, setErr] = useState<string | null>(null);
  const [ipa, setIpa] = useState<IpaResp | null>(null);
  const [audioUrl, setAudioUrl] = useState<string | null>(null);
  const [videoUrl, setVideoUrl] = useState<string | null>(null);

  // ğŸ”¹ STT + ë°œìŒ í‰ê°€ ìƒíƒœ
  const [stt, setStt] = useState<SttResp | null>(null);
  const [report, setReport] = useState<PronReport | null>(null);
  const [feedback, setFeedback] = useState<AiFeedback | null>(null);
  const [isEvaluating, setIsEvaluating] = useState(false);

  const media = useRef<MediaRecorder | null>(null);
  const chunks = useRef<Blob[]>([]);
  const streamRef = useRef<MediaStream | null>(null);

  async function start() {
    try {
      setErr(null);
      setIpa(null);
      setVideoUrl(null);
      setStt(null);
      setReport(null);
      setFeedback(null);

      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;
      const rec = new MediaRecorder(stream, { mimeType: "audio/webm" });
      chunks.current = [];

      rec.ondataavailable = (e) => e.data.size && chunks.current.push(e.data);

      rec.onstop = async () => {
        try {
          setPhase("ì—…ë¡œë“œ ì¤‘");
          const blob = new Blob(chunks.current, { type: "audio/webm" });
          setAudioUrl(URL.createObjectURL(blob));

          // 1ï¸âƒ£ STT (ìŒì„± â†’ í…ìŠ¤íŠ¸)
          setPhase("ì²˜ë¦¬ ì¤‘");
          const sttRes: SttResp = await callStt(blob);
          setStt(sttRes);

          const text = sttRes.rawText || sttRes.normText || "";
          if (!text) throw new Error("STT ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.");

          // 2ï¸âƒ£ IPA ë³€í™˜
          const ipaRes = await callIpa(text);
          setIpa(ipaRes);

          // 3ï¸âƒ£ ë°œìŒ í‰ê°€ + AI ìŠ¤íƒ€ì¼ í”¼ë“œë°±
          try {
            setIsEvaluating(true);

            // ê¸°ì¤€ ë¬¸ì¥: ìš°ì„  IPA ì›ë¬¸ì´ ìˆìœ¼ë©´ ê·¸ê±¸, ì•„ë‹ˆë©´ ì¸ì‹ í…ìŠ¤íŠ¸ ì‚¬ìš©
            const referenceText = ipaRes.original || text;
            const durationSec =
              typeof sttRes.duration === "number" ? sttRes.duration : 0;

            const evalRes = await callPronEval({
              referenceText,
              recognizedText: text,
              durationSec,
            });

            setReport(evalRes.report);
            setFeedback(evalRes.ai_feedback);
          } finally {
            setIsEvaluating(false);
          }

          // 4ï¸âƒ£ LipSync ì˜ìƒ ìƒì„±
          const lipSyncRes = await callLipSync(blob, "/face.jpg");
          const video =
            lipSyncRes?.output_video ||
            lipSyncRes?.output?.output_video ||
            lipSyncRes?.gooey?.output?.output_video;
          if (!video) throw new Error("ì˜ìƒ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
          setVideoUrl(video);

          setPhase("ì™„ë£Œ");
        } catch (e: any) {
          console.error(e);
          setErr(e?.message || "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
          setPhase("ì˜¤ë¥˜");
        } finally {
          chunks.current = [];
          streamRef.current?.getTracks().forEach((t) => t.stop());
          streamRef.current = null;
        }
      };

      media.current = rec;
      rec.start();
      setPhase("ë…¹ìŒ ì¤‘");
    } catch (e: any) {
      console.error(e);
      setErr("ë…¹ìŒ ê¶Œí•œì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
      setPhase("ì˜¤ë¥˜");
    }
  }

  function stop() {
    media.current?.stop();
  }

  return (
    <div className="w-full max-w-2xl mx-auto flex flex-col gap-4">
      <div className="flex items-center justify-center gap-3">
        <button
          onClick={phase === "ë…¹ìŒ ì¤‘" ? stop : start}
          className={`px-4 py-2 rounded text-white ${
            phase === "ë…¹ìŒ ì¤‘" ? "bg-red-600" : "bg-blue-600"
          }`}
          disabled={phase === "ì—…ë¡œë“œ ì¤‘" || phase === "ì²˜ë¦¬ ì¤‘"}
        >
          {phase === "ë…¹ìŒ ì¤‘" ? "ë…¹ìŒ ì¢…ë£Œ" : "ë…¹ìŒ ì‹œì‘"}
        </button>
        <span className="text-sm text-gray-600">
          {phase}
          {isEvaluating && " Â· ë°œìŒ í‰ê°€ ì¤‘..."}
        </span>
      </div>

      {err && (
        <div className="text-red-600 bg-red-50 border p-2 rounded">
          {err}
        </div>
      )}

      {audioUrl && (
        <div>
          <h2 className="font-semibold text-lg mb-1">ë…¹ìŒëœ ì˜¤ë””ì˜¤</h2>
          <audio src={audioUrl} controls className="w-full" />
        </div>
      )}

      {ipa && (
        <div className="border-t pt-4 space-y-2">
          <h2 className="text-xl font-bold">IPA ë° ë¡œë§ˆì ë³€í™˜ ê²°ê³¼</h2>
          <div>
            <div className="text-xs text-gray-500">ì›ë¬¸</div>
            <div className="text-lg">{ipa.original}</div>
          </div>
          <div>
            <div className="text-xs text-gray-500">IPA</div>
            <div className="font-mono break-words">{ipa.ipa}</div>
          </div>
          <div>
            <div className="text-xs text-gray-500">ë¡œë§ˆì í‘œê¸°</div>
            <div className="font-mono break-words">{ipa.romanized}</div>
          </div>
        </div>
      )}

      {/* ğŸ”¹ AI ë°œìŒ ë¦¬í¬íŠ¸ & í”¼ë“œë°± */}
      {report && feedback && (
        <div className="border-t pt-4 space-y-3">
          <h2 className="text-xl font-bold">AI ë°œìŒ ë¦¬í¬íŠ¸</h2>

          <div className="text-lg font-semibold">
            ì¢…í•© ì ìˆ˜:{" "}
            <span className="text-blue-600">{report.overall}</span>ì 
          </div>

          <div className="space-y-2 text-sm">
            <div>
              <div className="flex justify-between mb-1">
                <span>ì •í™•ë„</span>
                <span>{report.accuracy}%</span>
              </div>
              <div className="h-2 bg-gray-200 rounded-full overflow-hidden">
                <div
                  className="h-full bg-blue-500"
                  style={{ width: `${report.accuracy}%` }}
                />
              </div>
            </div>

            <div>
              <div className="flex justify-between mb-1">
                <span>ìœ ì°½ì„±</span>
                <span>
                  {report.fluency.score}% (
                  {report.fluency.syllables_per_second} ìŒì ˆ/ì´ˆ)
                </span>
              </div>
              <div className="h-2 bg-gray-200 rounded-full overflow-hidden">
                <div
                  className="h-full bg-green-500"
                  style={{ width: `${report.fluency.score}%` }}
                />
              </div>
            </div>
          </div>

          <div className="text-sm text-gray-800">
            <div className="font-semibold mb-1">AI ì½”ì¹˜ ìš”ì•½</div>
            <p>{feedback.summary}</p>
          </div>

          <div className="text-sm text-gray-800">
            <div className="font-semibold mb-1">ì—°ìŠµ íŒ</div>
            <ul className="list-disc list-inside space-y-1">
              {feedback.tips.map((tip, i) => (
                <li key={i}>{tip}</li>
              ))}
            </ul>
          </div>

          <div className="text-xs text-gray-500">
            ìˆ˜ì¤€: {feedback.level} Â· ì¶”ì²œ ë¬¸ì¥: â€œ
            {feedback.recommended_sentence}â€
          </div>
        </div>
      )}

      {videoUrl && (
        <div className="mt-3">
          <h2 className="text-xl font-bold">ê²°ê³¼ ì˜ìƒ</h2>
          <video
            src={videoUrl}
            controls
            className="w-full rounded-xl shadow"
          />
          <p className="text-xs text-gray-500 mt-1">
            AI ì…ëª¨ì–‘ ì‹œê°í™” ê²°ê³¼
          </p>
        </div>
      )}
    </div>
  );
}
